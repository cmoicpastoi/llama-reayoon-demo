apiVersion: v1
kind: ConfigMap
metadata:
  name: llama-web-content
data:
  index.html: |
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="UTF-8">
      <title>재윤님은 오늘도</title>
      <link rel="stylesheet" href="style.css">
    </head>
    <body>
      <div class="chat-box" id="chat-box"></div>
      <form id="chat-form">
        <input type="text" id="prompt" value="재윤은 오늘도" />
        <button type="submit">보내기</button>
      </form>
      <script src="script.js"></script>
    </body>
    </html>
  script.js: |
    document.getElementById("chat-form").addEventListener("submit", async function(e) {
      e.preventDefault();
      const prompt = document.getElementById("prompt").value;
      const chatBox = document.getElementById("chat-box");
      const loading = document.createElement("div");
      loading.className = "bubble you";
      loading.innerText = "⏳ 재윤님은 생각 중...><";
      chatBox.appendChild(loading);
      const res = await fetch("http://llama-api:8000/completion", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ prompt, n_predict: 50 })
      });
      const data = await res.json();
      loading.remove();
      const reply = document.createElement("div");
      reply.className = "bubble bot";
      reply.innerText = data.content;
      chatBox.appendChild(reply);
    });
  style.css: |
    body {
      font-family: sans-serif;
      background: #f4f4f4;
      padding: 20px;
    }
    .chat-box {
      max-width: 600px;
      margin: 0 auto 20px;
    }
    .bubble {
      padding: 10px 15px;
      border-radius: 15px;
      margin: 5px;
      max-width: 80%;
      display: inline-block;
    }
    .you {
      background: #d0f0ff;
      align-self: flex-end;
    }
    .bot {
      background: #ffe3e3;
    }

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama-api
  template:
    metadata:
      labels:
        app: llama-api
    spec:
      containers:
      - name: llama
        image: 130953309093.dkr.ecr.ap-northeast-2.amazonaws.com/llama-cpp-demo:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            apt update && apt install -y curl &&
            curl -L -o /models/model.gguf https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q4_K_M.gguf &&
            python3 -m llama_cpp.server --model /models/model.gguf --n_ctx 512 --host 0.0.0.0
        ports:
        - containerPort: 8000
        volumeMounts:
        - name: model-volume
          mountPath: /models
      volumes:
      - name: model-volume
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: llama-api
spec:
  selector:
    app: llama-api
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: NodePort

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama-web
  template:
    metadata:
      labels:
        app: llama-web
    spec:
      containers:
      - name: llama-web
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: web-content
          mountPath: /usr/share/nginx/html
      volumes:
      - name: web-content
        configMap:
          name: llama-web-content

---
apiVersion: v1
kind: Service
metadata:
  name: llama-web
spec:
  selector:
    app: llama-web
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
