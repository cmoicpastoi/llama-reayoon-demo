apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama-api
  template:
    metadata:
      labels:
        app: llama-api
    spec:
      containers:
      - name: llama
        image: ghcr.io/abetlen/llama-cpp-python:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            apt update && apt install -y curl &&
            curl -L -o /models/model.gguf https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q4_K_M.gguf &&
            python3 -m llama_cpp.server --model /models/model.gguf --n_ctx 512 --host 0.0.0.0
        ports:
        - containerPort: 8000
        volumeMounts:
        - name: model-volume
          mountPath: /models
      volumes:
      - name: model-volume
        emptyDir: {}